<!DOCTYPE html>
<!--
 * A Design by GraphBerry
 * Author: GraphBerry
 * Author URL: http://graphberry.com
 * License: http://graphberry.com/pages/license
-->
<html lang="en-us">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Kevin Choi's Site.</title>

	<!-- Load fonts -->
	<link href='http://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet' type='text/css'>
	<link href='http://fonts.googleapis.com/css?family=Lora' rel='stylesheet' type='text/css'>

	<!-- Load css styles -->
	<link rel="stylesheet" type="text/css" href="css/bootstrap.css" />
	<link rel="stylesheet" type="text/css" href="css/font-awesome.css" />
	<link rel="stylesheet" type="text/css" href="css/style.css" />
	




</head>
<body>
	<div class="jumbotron subpage home home-fullscreen" id="home">
		<div class="mask"></div>
		<a href="#" class="logo">
			<img src="img/profilepic2.png" alt="Moderno - Theme by GraphBerry.com">
		</a> 
		<a href="" class="menu-toggle" id="nav-expander"><i class="fa fa-bars"></i></a>
		<!-- Offsite navigation -->
		<nav class="menu">
			<a href="#" class="close"><i class="fa fa-close"></i></a>
			<h3>Menu</h3>
			<ul class="nav">
				<li><a data-scroll href="index.html">Home</a></li>
				<li><a data-scroll href="#portfolio">Portfolio</a></li>
				<li><a data-scroll href="#contact">Contact</a></li>
			</ul>

		</nav>
		<div class="container">
			<div class="header-info">
				<h1>Structure From Motion</h1>

			</div>
		</div>
	</div>
	<!-- Services section start -->
	

	<!-- Services section start -->
	<section id="topics">
		<div class="container">
			<div class="row">
				<div >
					<div class="topic-item">

						
						<h3>Generating 3D maps from 2D images!</h3>
						<p>Structure from Motion (SfM) takes a series of images, such as a video, and recreates the scene in 3D (structure) and traces the path that the camera took through the environment (motion). The structure-from-motion problem has only recently been solved yet it's impact in various fields has been enormous. It has allowed researchers to map out an entire city using pictures crowd-sourced from Flickr and Hollywood directors to insert computer generated characters into their scenes without green screens.
						</p>
						<center>
						<div class="topic-wrapper">
							<img class="topic-resize" src="./img/projects/sfm/image14.gif" />
							<img class="topic-resize" src="./img/projects/sfm/image20.gif" />
						</div>
						<p>Generated 3D points from 2D images</p>
						</center>
					</div>
				</div>

				<div >
					<div class="topic-item">
						
						<h3>Fundamental Matrix</h3>
						<p>To correlate the motion between several images first run a feature detection algorithm on image pairs. We can use the <a href= "https://en.wikipedia.org/wiki/Corner_detection">Harris Corner Detector</a> or the more robust <a href = "https://en.wikipedia.org/wiki/Speeded_up_robust_features">Speeded-Up-Robust-Features (SURF)</a> detector. By finding matching points between images we can begin to find the relationship between the cameras, which is embedded in the Fundamental Matrix. The Fundamental Matrix operates on a point on Image 1 and creates corresponding epipolar line on Image 2, which should pass through the matching point on Image 2. 
						</p>
						<center>
						<div class="topic-wrapper">
								<img class="topic-resize" src="./img/projects/sfm/image03.png" />
								<p>Feature matching</p>
								<img class="topic-resize" src="./img/projects/sfm/image04.png" />
								<p>Epipolar lines showing relative motion of camera</p>
						</div>
						</center>
					</div>
				</div>

				<div >
					<div class="topic-item">
						
						<h3>Estimating Camera Locations</h3>
						<p> What follows is a whole bunch of calculations to figure out where the pictures were taken in the real world relative to each other. Let's just take two pictures, from Camera 1 and 2. From one frame to the next, the camera can move up, down, left, right, and tilt in three different axes. Using the Fundamental matrix we can calculate four potential positions for Camera 2 relative to Camera 1. The trick to finding the right one is to triangulate the matched points from the previous step and pick the candidate that puts the most points in front of both cameras. Even after all these calculations, we only know the general direction of where Camera 2 lies, but not how far away it lies. We assume Camera 2 lies one unit away (unless we're given how big something in the picture is)and scale Camera 3,4,5... locations accordingly. If you're interested in all the math behind this check out my <a href = "https://docs.google.com/presentation/d/1ypGyTB3a5fSXWlj8nby5Hz1VKwRKb62v6w6dUSrxw3M/edit?usp=sharing"> presentation </a>.
						</p>
						<center>
						<div class="topic-wrapper">
								<img class="topic-resize" src="./img/projects/sfm/motionCalc.JPG" />
								
								<img class="topic-resize" src="./img/projects/sfm/triangulate.jpg" />
								<p>Lots of calculations to estimate camera locations</p>

								<img class="topic-resize" src="./img/projects/sfm/cameraTranslate.JPG" />
								<p>Figuring out virtual camera locations by triangulating matched features</p>
								
						</div>
						</center>
					</div>
				</div>				


				<div >
					<div class="topic-item">
						
						<h3>Results</h3>
						<p>Structure from motion works indoors and outdoors, as long as the feature detection algorithm can detect "interesting points" (blank walls are a problem). Our quantified results are listed in our <a href = "img/projects/sfm/StructureFromMotion.pdf">paper</a>. 
						</p>
						<center>
						<div class="topic-wrapper">
							<img class="topic-resize" src="./img/projects/sfm/image26.gif" />
							<img class="topic-resize" src="./img/projects/sfm/outside.JPG" />
						</div>
						<p>Outside Stacks Auditorium in UMich.</p>
						</center>
						<center>
						<div class="topic-wrapper">
							<img class="topic-resize" src="./img/projects/sfm/image30.gif" />
							<a href="./img/projects/sfm/image28.gif"><img class="topic-resize" src="img/projects/sfm/image28.gif" /></a>
						</div>
						<p>Indoor scene of ruler, can, eraser, and tape</p>
						</center>
						<p><br>What's really interesting here is that we can take any video (even from Youtube) and "reconstruct" the scene with 3D points. This method can also be used to give robots a sense of their surroundings with only one camera; this is also known as Visual Simultaneous Location and Mapping (VSLAM). </p>

					</div>
				</div>
				<!--<div class="col-md-4">
					<div class="service-item">
						<div class="icon"><i class="fa fa-life-ring"></i></div>
						<h3></h3>
						<p>


						</p>
					</div>
				</div> -->
			</div> 
		</div>
	</section>
	<!-- Services section end -->

	<!-- Services section end -->
	<!-- Portfolio section start -->
	
	<!-- Portfolio section end -->
	<!-- Contact section start -->
	<section id="contact">
		<div class="container">
			<header>
				<h2>Project Paper and Code</h2>
				<p><a href = "img/projects/sfm/StructureFromMotion.pdf">Project Paper</a>
					<br>
				<a href = "https://github.com/kev1nnsays/StructureFromMotion/tree/master">Matlab Code</a>
				</p>
			</header>

		</div>
	</section>
	<!-- Contact section end -->
	<!-- Footer start -->
	<footer>
		<div class="container">
			<div class="row">
				<div class="col-md-8">
					<p>Updated 2/2016 by Kevin Choi</p>
				</div>
	
			</div>
		</div>
	</footer>
	<!-- Footer end  -->

	<!-- Load jQuery -->
	<script type="text/javascript" src="js/jquery-1.11.2.min.js"></script>

	<!-- Load Booststrap -->
	<script type="text/javascript" src="js/bootstrap.js"></script>

	<script type="text/javascript" src="js/smooth-scroll.js"></script>

	<script type="text/javascript" src="https://maps.googleapis.com/maps/api/js?sensor=false"></script>

	<!-- Load custom js for theme -->
	<script type="text/javascript" src="js/app.js"></script>
</body>
</html>